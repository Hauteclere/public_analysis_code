{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUT MDM Profiling\n",
    "\n",
    "This document details the code and techniques used in the strategic profiling exercises during the construction of the QUT MDM system. \n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Associated Files\n",
    "\n",
    "| **File**  | **Description**  |\n",
    "|---|---|\n",
    "|  `handover.ipynb` | The primary document is entitled `handover.ipynb`. This file contains the desription of the process, as well as the code which performs the analysis and presents the results.  |\n",
    "|  `requirements.txt` | The `requirements.txt` file details the Python libraries which are required to run the analysis. For information on how to set up a working environment see the **Installation** section below.  |\n",
    "|  `handover.html` |  The `handover.html` file is a static pdf copy of the `handover.ipynb` file, created for ease of reading outside of a coding environment. It contains scrollable codebocks. |\n",
    "|  `handover.pdf` |  The `handover.pdf` file is a static pdf copy of the `handover.ipynb` file, created for ease of annotation outside of a coding environment. |\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "The following is a quick how-to guide for setting up and running this analysis on your machine. If you are already equipped to run data analysis using Python and Jupyter, feel free to skip ahead.\n",
    "\n",
    "#### Pre-requisites:\n",
    "- This analysis was conducted using the `Python` programming language, using the `Jupyter Notebook` REPL platform. To open and manipulate the `main.ipynb` file, a code editor is required. We recommend [`VS Code`](https://code.visualstudio.com/download), running the [`Jupyter`](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) extension. \n",
    "\n",
    "- To run the code, `Python 3.10+` is recommended. Instructions on installing Python for various operating systems can be found [here](https://wsvincent.com/install-python/).\n",
    "\n",
    "- You will also need [`pip`](https://pip.pypa.io/en/stable/installation/) in order to install dependencies.\n",
    "\n",
    "#### Creating a virtual environment:\n",
    "\n",
    "1. Begin by installing `virtualenv` globally on your machine. You can do this by  the command ```python3 -m pip install virtualenv``` in your terminal.\n",
    "1. In the terminal, navigate into the directory containing the analysis files.\n",
    "1. Next, use `virtualenv` to create a virtual environment in which to run the analysis. The command is ```python3 -m virtualenv venv```\n",
    "1. Activate the virual environment. On Unix systems the command is ```source ./venv/bin/activate```. On Windows you should use ```.\\venv\\Scripts\\activate``` (you'll need to perform this step every time you want to work with the file.)\n",
    "1. Install the project dependencies by running ```python3 -m pip install -r requirements.txt```\n",
    "1. *That's it, you are now ready to run the file!*\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Input Data:\n",
    "Since this document and it's associated files have been prepared for dissemination to various internal stakeholders, the input data which were used to generate the analysis have not been included in the file tree. A description of the input data can be found below in the. To reproduce of extend this analysis, data will need to be supplied of the same or similar format to the original inputs.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "The code for profiling and the results are set out below with annotations. Depending on the inputs and goals, modification/adaptation may be required if you want to repeat/extend the analysis.\n",
    "\n",
    "### Importing Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import phonenumbers\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "from typing import Optional\n",
    "from validate_email import validate_email as _validate_email\n",
    "from IPython.display import display\n",
    "from pandas_profiling import ProfileReport\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "\n",
    "This section contains code that defines settings for the rest of the profiling exercise. Making modifications here is the simplest and safest way of tweaking the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary defines the locations of the input .csv files\n",
    "# Note that the files listed here are not included in the distributed version of this handover\n",
    "# To run this analysis, you will need to obtain data extracts containing the same/similar information\n",
    "# It may be necessary to modify code throughout this file to suit your inputs\n",
    "INPUT_DATA_ADDRESSES = {\n",
    "    \"ascender_employees\": \"./source_data/employee_grab.csv\",\n",
    "    \"dep_prospects\": \"./source_data/dep_grab.csv\",\n",
    "    \"studylink_applicants\": \"./source_data/studylink_grab.csv\",\n",
    "    \"sams_students\": \"./source_data/sams_student_grab.csv\",\n",
    "    \"sams_applicants\": \"./source_data/sams_applicant_grab.csv\"\n",
    "}\n",
    "\n",
    "# This dictionary records the fields in each data set that we will use as \"primary key\"-style identifiers \n",
    "PK_FIELDS = {\n",
    "    \"ascender_employees\": \"EMPLOYEE_ID\",\n",
    "    \"dep_prospects\": \"CONTACT_ID\",\n",
    "    \"studylink_applicants\": \"APPLICANT_ID\",\n",
    "    \"sams_students\": \"QUT_GUID\",\n",
    "    \"sams_applicants\": \"QUT_GUID\"\n",
    "}\n",
    "\n",
    "# A list of the pairs of columns on which we will detect potential duplicates\n",
    "DUPLICATE_CRITERIA = [\n",
    "    (\"PHONE_MOBILE\", \"GIVEN_NAME\"),\n",
    "    (\"PHONE_MOBILE\", \"DOB\"),\n",
    "    (\"PERSONAL_EMAIL\", \"GIVEN_NAME\"),\n",
    "    (\"PERSONAL_EMAIL\", \"DOB\")\n",
    "]\n",
    "\n",
    "# A dict of the optimal ways to align linked entries in datasets\n",
    "MATCHFIELDS = {\n",
    "    \"QUT_GUID\": [\n",
    "        (\"dep_prospects\", \"ascender_employees\"),\n",
    "        (\"ascender_employees\", \"sams_applicants\"),\n",
    "        (\"ascender_employees\", \"sams_students\"),\n",
    "        (\"sams_students\", \"sams_applicants\"),\n",
    "    ],\n",
    "    \"STUDENT_ID\": [\n",
    "        (\"sams_students\", \"studylink_applicants\"),\n",
    "        (\"studylink_applicants\", \"sams_applicants\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "# This dict governs how to choose a value for a field when different sources have different values for that field for a single person\n",
    "# Note that a valid value always trumps an invalid value, and a non-null value always trumps a null value\n",
    "FIELD_SYSTEM_PRECEDENCES = {\n",
    "    'ADDR1_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'ADDR2_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'ADDR3_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'CNTRY_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'DOB': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'FAMILY_NAME': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'FULL_NAME': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'GENDER': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'GIVEN_NAME': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'OTHER_NAME': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'PERSONAL_EMAIL': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'PHONE_MOBILE': [\"sams_applicants\", \"studylink_applicants\", \"sams_students\", \"ascender_employees\", \"dep_prospects\"],\n",
    "    'POSTC_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'PREFERRED_NAME': [\"sams_applicants\", \"ascender_employees\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'SALUTATION': [\"sams_applicants\", \"ascender_employees\", \"studylink_applicants\", \"sams_students\", \"dep_prospects\"],\n",
    "    'STATE_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"],\n",
    "    'SUBRB_HOME': [\"ascender_employees\", \"sams_applicants\", \"sams_students\", \"studylink_applicants\", \"dep_prospects\"]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "This section reads data from the files specified in the `INPUT_DATA_ADDRESSES` setttings variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read each of the files into a value in a dictionary.\n",
    "input_data = {dataset_name: pd.read_csv(file_location, dtype=str) for dataset_name, file_location in INPUT_DATA_ADDRESSES.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Exploratory Reports\n",
    "\n",
    "This section creates the exploratory reports. Simply uncomment and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name, dataset in input_data.items():\n",
    "#    report = ProfileReport(dataset, minimal=True, vars={\"cat\": {\"n_obs\": 20}})\n",
    "#    report.to_file(f\"./exploratory_profiles/{dataset_name}_profile.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness:\n",
    "The following block of code calculates the completeness of each column in each dataset, and displays these values in a series of convenient tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We iterate through each dataset\n",
    "for dataset_name, dataset in input_data.items():\n",
    "\n",
    "    # First we calculate how long the dataset is\n",
    "    dataset_length = len(dataset)\n",
    "    \n",
    "    # Then we create a temporary dataframe to hold our calculations\n",
    "    to_display = pd.DataFrame({\n",
    "        # The first column of the temp dataframe contains the names of each column in the dataset\n",
    "        \"column\": [column for column in dataset.columns],\n",
    "        # The second column shows how many non-null values there are for each column\n",
    "        \"count\": [len(dataset[dataset[column].notna()]) for column in dataset.columns],\n",
    "        # The third column calculates the relative frequency of non-null values \n",
    "        \"completeness\": [len(dataset[dataset[column].notna()])/dataset_length for column in dataset.columns],\n",
    "        # The fourth column gives us an example value from the column\n",
    "        \"sample\": [dataset[dataset[column].notna()][column].mode()[0] if len(dataset[dataset[column].notna()][column])>0 else np.nan for column in dataset]\n",
    "    # we apply a little styling to our temp dataframe so that the completeness column is displayed as a percentage\n",
    "    }).style.format({\n",
    "        \"completeness\": '{:,.2%}'.format\n",
    "    })\n",
    "\n",
    "    # A quick string output to show what data source we're talking about and how big it is\n",
    "    print(f\"\\n\\n{dataset_name} ({dataset_length} records):\\n\".upper())\n",
    "    # This display() function is the one we imported from Ipython up the top - it just improves readability\n",
    "    display(to_display)\n",
    "\n",
    "    print(\"\\n-------------------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity\n",
    "\n",
    "Calculating validity is complex. First let's define some functions to automate the work for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define an alpha regex to check that a string contains only acceptable characters for names\n",
    "ALPHA_REGEX = re.compile(\"^[A-Za-zÀ-ÖØ-öø-ÿ -./']*$\")\n",
    "\n",
    "# A function to validate names.\n",
    "def validate_name(name_string, banned_values=[], polluting_values=[]):\n",
    "    \"\"\"Validates a value by checking that it is an acceptable name.\n",
    "    \n",
    "    Checks that the value is a string containing only alphabetical characters \n",
    "    (including diacritics), plus spaces, fullstops, dashes, apostophes, and \n",
    "    forward-slashes. Currently fails the empty string \"\" as invalid.\n",
    "    \n",
    "    Args:\n",
    "        name_string: Any value that is potentially a name. \n",
    "        banned_values: A list of specific values which are invalid.\n",
    "        polluting_values: A list of values which cannot appear as substrings.\n",
    "\n",
    "    Returns: \n",
    "        A boolean.\n",
    "    \"\"\"\n",
    "    return (isinstance(name_string, str) \n",
    "            and bool(ALPHA_REGEX.match(name_string)) \n",
    "            and not any([name_string==value for value in banned_values]) \n",
    "            and not any([value in name_string for value in polluting_values]))\n",
    "\n",
    "# A function to validate birthdates.\n",
    "def validate_birthdate(date_string, date_format, banned_values=[], earliest_date=None, latest_date=None):\n",
    "    \"\"\"Validates a value by checking that it is an acceptable birthdate.\n",
    "\n",
    "    Attempts to apply the datetime.strptime method to the value, returning \n",
    "    False on failure. Then rules out common \"default\" birthdates, i.e., \n",
    "    \"01/01/1901\".\n",
    "\n",
    "    Args:\n",
    "        date_string: Any value that is potentially a birthdate.\n",
    "        date_format: A time format conforming to the 1998 C standard, example:\n",
    "            '%Y-%m-%d', '%d/%m/%Y', etc...\n",
    "        banned_values: A list of specific values which are invalid.\n",
    "        earliest_date: The earliest allowable birthday\n",
    "        latest_date: The latest allowable birthday\n",
    "    \n",
    "    Returns: \n",
    "        A boolean.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grokked_date = datetime.datetime.strptime(date_string, date_format)\n",
    "        if earliest_date and grokked_date < earliest_date:\n",
    "            return False\n",
    "        if latest_date and grokked_date > latest_date:\n",
    "            return False\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "    return not date_string in banned_values\n",
    "\n",
    "# A function to validate email addresses\n",
    "def validate_email(email_string, banned_values=[], polluting_values=[\"qut.edu.au\"] ):\n",
    "    \"\"\"Validates a value by checking that it is an acceptable email address.\n",
    "\n",
    "    Checks format with regex and returns False for blacklisted domains \n",
    "    (i.e., common throwaway addresses). For individual address validation\n",
    "    it is possible to run _validat_email with check_dns and check_smtp set\n",
    "    to True, however this is not practical for large datasets.\n",
    "\n",
    "    Args:\n",
    "        email_string: Any value that is potentially an email address.\n",
    "        banned_values: A list of specific values which are invalid.\n",
    "        polluting_values: A list of values which cannot appear as substrings.\n",
    "\n",
    "    Returns: \n",
    "        A boolean.\n",
    "    \"\"\"\n",
    "    return (isinstance(email_string, str) \n",
    "            and _validate_email(\n",
    "                email_address=email_string, \n",
    "                check_format=True, \n",
    "                check_blacklist=True, \n",
    "                check_dns=False, \n",
    "                check_smtp=False) \n",
    "            and not any([email_string==value for value in banned_values]) \n",
    "            and not any([value in email_string for value in polluting_values]))\n",
    "\n",
    "# A function to prepare mobile phone numbers for validation\n",
    "def _default_mobile_value_treatment(mobile_value):\n",
    "    \"\"\"Attempts to standardise a mobile string prior to validation.\n",
    "\n",
    "    This is a good candidate for a customisation, depending on your data.\n",
    "    Process:\n",
    "        - All non-numerical characters are removed.\n",
    "        - Nine-digit numbers are assumed to be Australian mobiles with the \n",
    "            leading 0 omitted; the 0 is prepended. \n",
    "        - 10 digit numbers beginning with \"04\" are assumed to be Australian \n",
    "            mobiles; these are parsed as-is. \n",
    "        - All other numbers are assumed to be international numbers, and are\n",
    "            prepended with \"+\".\n",
    "    \n",
    "    Args: \n",
    "        mobile_value: the value to treat.\n",
    "\n",
    "    Returns:\n",
    "        A treated string representing a mobile phone number.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        mobile_string = str(int(float(mobile_value)))\n",
    "    except ValueError:\n",
    "        mobile_string = str(mobile_value)\n",
    "\n",
    "    mobile_string=re.sub('[^0-9]','', mobile_string)\n",
    "\n",
    "\n",
    "    if len(mobile_string)==9:\n",
    "        mobile_string = f\"0{mobile_string}\"\n",
    "    elif not (len(mobile_string)==10 and mobile_string[0:2]==\"04\"):\n",
    "        mobile_string=f\"+{mobile_string}\"\n",
    "    \n",
    "    return mobile_string\n",
    "\n",
    "# A function to validate mobile phone numbers\n",
    "def validate_mobile_string(mobile_value, treatment=_default_mobile_value_treatment, banned_values=[]):\n",
    "    \"\"\"Validates a mobile string by attempting to parse it.\n",
    "    \n",
    "    Uses Google's LibPhoneNumbers parser.\n",
    "\n",
    "    Args:\n",
    "        mobile_value: Any value that is potentially a mobile phone number.\n",
    "        treatment: A function to standardise values. You should probably \n",
    "            override the default here, especially if you haven't read that\n",
    "            function. Failing all else just use `lambda x: x` to validate the\n",
    "            value as-is.\n",
    "        banned_values: A list of specific values which are invalid.\n",
    "        polluting_values: A list of values which cannot appear as substrings.\n",
    "\n",
    "    Returns: \n",
    "        A boolean.    \n",
    "    \"\"\"\n",
    "    if any([mobile_value==value for value in banned_values]):\n",
    "        return False\n",
    "    try:\n",
    "        parsed = phonenumbers.parse(treatment(mobile_value), region=\"AU\")\n",
    "    except phonenumbers.NumberParseException:\n",
    "        return False\n",
    "    return phonenumbers.is_valid_number(parsed)\n",
    "\n",
    "# A handy dictionary to contain all of our validation functions\n",
    "# We wrap the function in a lambda, inserting the arguments we want to use for each field.\n",
    "validation_dict = {\n",
    "    \"DOB\": lambda value: validate_birthdate(value, date_format='%Y-%m-%d', earliest_date=datetime.datetime(1922, 1,1), latest_date=datetime.datetime(2008, 1, 1)),\n",
    "    \"PERSONAL_EMAIL\": lambda value: np.nan if value is np.nan else validate_email(value),\n",
    "    \"SALUTATION\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"GIVEN_NAME\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"OTHER_NAME\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"FAMILY_NAME\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"FULL_NAME\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"PREFERRED_NAME\": lambda value: np.nan if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"PHONE_MOBILE\": lambda value: np.nan if value is np.nan else validate_mobile_string(value),\n",
    "    \"GENDER\": lambda value: np.nan if value is np.nan else value in [\"F\", \"M\", \"X\"],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get down to business..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code we're about to run generates some irrelevant warnings, so let's catch them\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "    # We iterate through each dataset\n",
    "    for dataset_name, dataset in input_data.items():\n",
    "\n",
    "        # first, we need one temp frame to hold the results of our validations\n",
    "        validity_frame = pd.DataFrame()\n",
    "\n",
    "        # our validity_frame mirrors the\n",
    "        for column in dataset.columns:\n",
    "            if column in validation_dict:\n",
    "                validity_frame[column] = dataset[column].apply(validation_dict[column])    \n",
    "\n",
    "        to_display = pd.DataFrame({\n",
    "            # The first column of the temp dataframe contains the names of each column in the dataset\n",
    "            \"column\": [column for column in validity_frame.columns],\n",
    "            # The second column shows how many non-null values there are for each column\n",
    "            \"count\": [len(dataset[dataset[column].notna()]) for column in validity_frame.columns],\n",
    "            # The third column calculates how many valid values there are in each column \n",
    "            \"valid\": [len(validity_frame[validity_frame[column].notna()][validity_frame[column]==True]) for column in validity_frame.columns],\n",
    "        \n",
    "        })\n",
    "\n",
    "        # Finally let's add another column to show validity as a percentage\n",
    "        to_display[\"validity\"] = to_display[\"valid\"]/to_display[\"count\"]\n",
    "\n",
    "        print(f\"\\n\\n{dataset_name.upper()}\")\n",
    "        display(to_display.style.format({\n",
    "            # we apply a little styling to our temp dataframe so that the validity column is displayed as a percentage\n",
    "            \"validity\": '{:,.2%}'.format\n",
    "        }))\n",
    "        print(\"\\n-------------------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out we are going to quarantine records that have invalid field values though. Let's look at the impact of that. First, what happens if we allow null values but disallow invalid ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to prepare mobile phone numbers for validation\n",
    "def _default_mobile_value_treatment(mobile_value):\n",
    "    \"\"\"Attempts to standardise a mobile string prior to validation.\n",
    "\n",
    "    This is a good candidate for a customisation, depending on your data.\n",
    "    Process:\n",
    "        - All non-numerical characters are removed.\n",
    "        - Nine-digit numbers are assumed to be Australian mobiles with the \n",
    "            leading 0 omitted; the 0 is prepended. \n",
    "        - 10 digit numbers beginning with \"04\" are assumed to be Australian \n",
    "            mobiles; these are parsed as-is. \n",
    "        - All other numbers are assumed to be international numbers, and are\n",
    "            prepended with \"+\".\n",
    "    \n",
    "    Args: \n",
    "        mobile_value: the value to treat.\n",
    "\n",
    "    Returns:\n",
    "        A treated string representing a mobile phone number.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        mobile_string = str(int(float(mobile_value)))\n",
    "    except ValueError:\n",
    "        mobile_string = str(mobile_value)\n",
    "\n",
    "    mobile_string=re.sub('[^0-9+]','', mobile_string)\n",
    "\n",
    "    if mobile_string[:4] == \"6161\":\n",
    "        mobile_string=f\"+{mobile_string[2:]}\"\n",
    "    elif mobile_string[:5] == \"+6161\":\n",
    "        mobile_string=f\"+{mobile_string[3:]}\"\n",
    "\n",
    "    if len(mobile_string) == 8:\n",
    "        mobile_string=f\"+617{mobile_string}\"\n",
    "\n",
    "    if len(mobile_string)==9:\n",
    "        mobile_string = f\"+61{mobile_string}\"\n",
    "    \n",
    "    if (len(mobile_string)==10 and mobile_string[0:2] in [\"04\", \"02\", \"03\", \"07\", \"08\"]):\n",
    "        mobile_string=f\"+61{mobile_string[1:]}\"\n",
    "    elif len(mobile_string) >= 10 and not mobile_string[0] in [\"+\", \"00\"]:\n",
    "        mobile_string=f\"+{mobile_string}\"\n",
    "    \n",
    "\n",
    "\n",
    "    return mobile_string\n",
    "\n",
    "# A function to validate mobile phone numbers\n",
    "def validate_mobile_string(mobile_value, treatment=_default_mobile_value_treatment, banned_values=[], try_region=\"AU\"):\n",
    "    \"\"\"Validates a mobile string by attempting to parse it.\n",
    "    \n",
    "    Uses Google's LibPhoneNumbers parser.\n",
    "\n",
    "    Args:\n",
    "        mobile_value: Any value that is potentially a mobile phone number.\n",
    "        treatment: A function to standardise values. You should probably \n",
    "            override the default here, especially if you haven't read that\n",
    "            function. Failing all else just use `lambda x: x` to validate the\n",
    "            value as-is.\n",
    "        banned_values: A list of specific values which are invalid.\n",
    "        polluting_values: A list of values which cannot appear as substrings.\n",
    "\n",
    "    Returns: \n",
    "        A boolean.    \n",
    "    \"\"\"\n",
    "    if any([mobile_value==value for value in banned_values]):\n",
    "        return False\n",
    "    try:\n",
    "        parsed = phonenumbers.parse(treatment(mobile_value), region=try_region)\n",
    "    except phonenumbers.NumberParseException:\n",
    "        return False\n",
    "    return phonenumbers.is_valid_number(parsed)\n",
    "\n",
    "def convert_to_cldr(region):\n",
    "    match region:\n",
    "        case \"CHINA\":\n",
    "            return \"CN\"\n",
    "        case \"INDIA\":\n",
    "            return \"IN\"\n",
    "        case \"HONG KONG\":\n",
    "            return \"HK\"\n",
    "        case \"PHILIPPINES (THE)\":\n",
    "            return \"PH\"\n",
    "        case \"VIET NAM\":\n",
    "            return \"VN\"\n",
    "        case \"VIETNAM\":\n",
    "            return \"VN\"\n",
    "        case \"SAUDI ARABIA\":\n",
    "            return \"SA\"\n",
    "        case \"THAILAND\":\n",
    "            return \"TH\"\n",
    "        case \"SRI LANKA\":\n",
    "            return \"LK\"\n",
    "        case \"BANGLADESH\":\n",
    "            return \"BD\"\n",
    "        case \"GERMANY\":\n",
    "            return \"DE\"\n",
    "        case \"CAMEROON\":\n",
    "            return \"CM\"\n",
    "        case \"SOUTH AFRICA\":\n",
    "            return \"ZA\"\n",
    "        case \"MALAYSIA\":\n",
    "            return \"MY\"\n",
    "        case \"UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND\":\n",
    "            return \"GB\"\n",
    "        case \"ICELAND\":\n",
    "            return \"IS\"\n",
    "        case \"KAZAKHSTAN\":\n",
    "            return \"KZ\"\n",
    "        case \"FRANCE\":\n",
    "            return \"FR\"\n",
    "        case \"UNITED ARAB EMIRATES (THE)\":\n",
    "            return \"AE\"\n",
    "        case \"PAKISTAN\":\n",
    "            return \"PK\"\n",
    "        case \"BRAZIL\":\n",
    "            return \"BR\"\n",
    "        case \"PAPUA NEW GUINEA\":\n",
    "            return \"PG\"\n",
    "        case \"IRAN (ISLAMIC REPUBLIC OF)\":\n",
    "            return \"IR\"\n",
    "        case \"TAIWAN (PROVINCE OF CHINA)\":\n",
    "            return \"TW\"\n",
    "        case \"SINGAPORE\":\n",
    "            return \"SG\"\n",
    "        case \"JAPAN\":\n",
    "            return \"JP\"\n",
    "        case \"KOREA (THE REPUBLIC OF)\":\n",
    "            return \"KR\"\n",
    "        case \"ETHIOPIA\":\n",
    "            return \"ET\"\n",
    "        case \"CANADA\":\n",
    "            return \"CA\"\n",
    "        case \"MACAO\":\n",
    "            return \"MO\"\n",
    "        case \"MALAYSIA\":\n",
    "            return \"MY\"\n",
    "        \n",
    "        case other:\n",
    "            return region\n",
    "\n",
    "def try_and_validate(row):\n",
    "    mynum = row[\"PHONE_MOBILE\"]\n",
    "    if mynum[:4] == \"0011\" or mynum[:5] == \"+0011\":\n",
    "        mynum = f\"+{mynum[4:]}\"\n",
    "    if mynum[:2] == \"00\" or mynum[:3] == \"+00\":\n",
    "        mynum = f\"+{mynum[2:]}\"\n",
    "    return validate_mobile_string(mynum, treatment=lambda x: x, try_region=convert_to_cldr(str(row[\"CNTRY_HOME\"])))\n",
    "\n",
    "validation_dict = {\n",
    "    \"DOB\": lambda value: True if value is np.nan else validate_birthdate(value, date_format='%Y-%m-%d', earliest_date=datetime.datetime(1922, 1,1), latest_date=datetime.datetime(2008, 1, 1)),\n",
    "    \"PERSONAL_EMAIL\": lambda value: True if value is np.nan else validate_email(value, polluting_values=[]),\n",
    "    \"SALUTATION\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"GIVEN_NAME\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"OTHER_NAME\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"FAMILY_NAME\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"FULL_NAME\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"PREFERRED_NAME\": lambda value: True if value is np.nan else validate_name(value, banned_values=[\"\", \".\", \"-\"], polluting_values=[\"Unknown\", \"UNKNOWN\", \"unknown\", \"DUPLICATE\", \"Duplicate\", \"duplicate\"]),\n",
    "    \"PHONE_MOBILE\": lambda value: True if value is np.nan else validate_mobile_string(value),\n",
    "}\n",
    "\n",
    "# The code we're about to run generates some irrelevant warnings, so let's catch them\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "    # We iterate through each dataset\n",
    "    for dataset_name, dataset in input_data.items():\n",
    "        print(dataset_name.upper())\n",
    "        # first, we need one temp frame to hold the results of our validations\n",
    "        validity_frame = dataset.copy(deep=True)\n",
    "\n",
    "        if not \"CNTRY_HOME\" in dataset.columns:\n",
    "            bad = validity_frame[~validity_frame[\"PHONE_MOBILE\"].apply(validation_dict[\"PHONE_MOBILE\"])][[\"PHONE_MOBILE\"]]\n",
    "            print(f\"\\ndropped {len(bad)} of {len(dataset)} ({'{:.2%}'.format(len(bad)/len(dataset))})\")\n",
    "            display(bad.head(5))\n",
    "        else:\n",
    "            bad = validity_frame[~validity_frame[\"PHONE_MOBILE\"].apply(validation_dict[\"PHONE_MOBILE\"])][[\"PHONE_MOBILE\", \"CNTRY_HOME\"]]\n",
    "            bad[\"fixable with country code\"] = bad.apply(try_and_validate, axis=1)\n",
    "            print(f\"\\ndropped {len(bad[~bad['fixable with country code']])} of {len(dataset)} ({'{:.2%}'.format(len(bad[~bad['fixable with country code']])/len(dataset))})\")\n",
    "            display(bad[~bad['fixable with country code']].head(5))\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"for column in dataset.columns:\n",
    "            if column in validation_dict:\n",
    "                bad = validity_frame[~validity_frame[column].apply(validation_dict[column])][column]\n",
    "                print(f\"\\ndropped {len(bad)} from {column}:\")\n",
    "                display(bad.head())\n",
    "                validity_frame = validity_frame[validity_frame[column].apply(validation_dict[column])]\"\"\"\n",
    "\n",
    "        \"\"\"print(f\"{dataset_name} original length: {len(dataset)}\\nDROPPED: {len(dataset)-len(validity_frame)}\")\"\"\"\n",
    "        print(\"\\n-------------------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniqueness\n",
    "\n",
    "Next let's take a look at whether or not there are any duplicate records in each dataset. We'll need a function for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a function to turn up suspected duplicates for stewarding\n",
    "def find_dupes(frame: pd.DataFrame, pk_col: str, first_column: str, second_column: Optional[str]=None, ignore_originals: Optional[bool]=True) -> pd.DataFrame:\n",
    "    \"\"\"Creates a dataframe containing rows that are suspected duplicate records.\n",
    "    Adds an extra column listing which other row they are a suspected dupe of.\n",
    "\n",
    "    Args:\n",
    "        frame: The dataframe to scan for duplicates\n",
    "        pk_col: A column containing a pk-like value for this dataset\n",
    "        first_column: The column on which to compare records.\n",
    "        second_column: An optional second column to compare on. \n",
    "        ignore_originals: Optionally ignore the first instance in a set of duplicated rows\n",
    "\n",
    "    Returns:\n",
    "        A pandas dataframe containing all identified duplicates, flagged with the primary key of they row they duplicate\n",
    "    \"\"\"\n",
    "    # turning off warnings because pandas doesn't know what's good for it.\n",
    "    with pd.option_context('mode.chained_assignment', None):\n",
    "        \n",
    "        # skip rows that are null \n",
    "        notnullframe = frame[~frame[first_column].isna()]\n",
    "        if not second_column is None:\n",
    "            notnullframe = notnullframe[~notnullframe[second_column].isna()]\n",
    "\n",
    "        # need to make a copy so we don't mess with the original\n",
    "        temp_frame = notnullframe.copy(deep=True)\n",
    "        \n",
    "        # need a column to record why the dupe was flagged\n",
    "        temp_frame[\"DUPLICATE_OF\"] = np.nan\n",
    "        \n",
    "        # Add a temp column to hold our duplicate criterion\n",
    "        if not second_column is None:       \n",
    "            temp_frame[f\"dupedetector\"] = temp_frame[first_column].map(str) + temp_frame[second_column].map(str)\n",
    "        else:\n",
    "            temp_frame[f\"dupedetector\"] = temp_frame[first_column]\n",
    "        \n",
    "        # get the dupes\n",
    "        dupes = temp_frame[temp_frame.duplicated(subset=f\"dupedetector\", keep=False)]\n",
    "\n",
    "        # flag each dupe with its first instance\n",
    "        for i, g in dupes.groupby(f\"dupedetector\"):\n",
    "            for index, row in g.iterrows():\n",
    "                dupes.loc[index, f\"DUPLICATE_OF\"] = g[pk_col].iloc[0]\n",
    "\n",
    "        # delete that temporary column\n",
    "        dupes = dupes.drop(f\"dupedetector\", axis=1)\n",
    "\n",
    "        # optionally drop any row that is registered as a duplicate of itself\n",
    "        if ignore_originals:\n",
    "            dupes = dupes[dupes[f\"DUPLICATE_OF\"]!=dupes[pk_col]]  \n",
    "        \n",
    "        # return the dupes\n",
    "        return dupes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can analyse uniqueness and filter any potential duplicates out of the sources ahead of a test merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source, dataset in input_data.items():\n",
    "    if 'PER_EMAIL_ADDR' in dataset.columns:\n",
    "        input_data[source] = dataset.rename(columns={\"PER_EMAIL_ADDR\": 'PERSONAL_EMAIL'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need somewhere to store the duplicates we detect\n",
    "all_dupes = dict()\n",
    "\n",
    "# Iterate through each source, collecting duplicates based on each duplicate detection criterion\n",
    "for source, dataset in input_data.items():\n",
    "    all_dupes[source] = dict()\n",
    "    for col1, col2 in DUPLICATE_CRITERIA:\n",
    "        all_dupes[source][f\"{col1}+{col2}\"] = find_dupes(input_data[source], PK_FIELDS[source], col1, col2, True)\n",
    "\n",
    "# For each source, collect all the duplicates and group them together\n",
    "# If any were flagged twice, drop the double-ups\n",
    "for source, dupedict in all_dupes.items():\n",
    "    all_dupes[source][\"all\"] = pd.concat([dupeset for dupeset in dupedict.values()]).drop_duplicates(subset=PK_FIELDS[source], keep=\"first\")\n",
    "    \n",
    "    # Uncomment the below for a sample of the flagged duplicates:\n",
    "    # print(f\"\\n\\n{source}\")\n",
    "    # display(all_dupes[source][\"all\"].sort_values(\"DUPLICATE_OF\").head(6))\n",
    "\n",
    "# We want to display the uniqueness for each source\n",
    "to_display = pd.DataFrame({\n",
    "    \"source\": [sourcename for sourcename in input_data.keys()],\n",
    "    \"length\": [len(dataset) for dataset in input_data.values()],\n",
    "    \"flagged as duplicate\": [len(all_dupes[source][\"all\"]) for source in [sourcename for sourcename in input_data.keys()]] \n",
    "})\n",
    "to_display[\"uniqueness\"] = 1 - to_display[\"flagged as duplicate\"]/to_display[\"length\"]\n",
    "\n",
    "display(to_display.style.format({\n",
    "            # we apply a little styling to our temp dataframe so that the validity column is displayed as a percentage\n",
    "            \"uniqueness\": '{:,.2%}'.format\n",
    "        }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniqueness looks good, let's filter out those dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_merge = {\n",
    "    # We can just concatenate the list of duplicates with the full dataset, then drop any rows that have a duplicate primary key\n",
    "    # We also need to drop the \"DUPLICATE_OF\" column\n",
    "    sourcename: pd.concat([duped_dataset, all_dupes[sourcename][\"all\"]]).drop_duplicates(subset=PK_FIELDS[sourcename], keep=False).drop(columns=\"DUPLICATE_OF\") for sourcename, duped_dataset in input_data.items()\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Merging\n",
    "\n",
    "Next we'll need to merge the data into a \"Master Person\" analogue. Up until now we have been using `pandas.Dataframe` objects to perform our analysis, but since we have a lot of data and need to do some complex joins, dataframes will be too computationally expensive moving forward. Instead we will convert our data to hash tables.\n",
    "\n",
    "### Hash Tables\n",
    "\n",
    "First let's create some convenient tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(framename: str, frame: pd.DataFrame, keyfield: str) -> dict:\n",
    "    \"\"\"Converts a dataframe to a hash table. \n",
    "    \n",
    "    Choose a field with 100% uniqueness and completeness for the keyfield.\n",
    "    \n",
    "    Args:\n",
    "        framename: The name of the dataset being converted.\n",
    "        frame: A pandas dataframe object to be converted.\n",
    "        keyfield: The name of the column in the dataframe which should be used as they keys for the hash table. \n",
    "\n",
    "    Returns: \n",
    "        A dictionary.    \n",
    "    \"\"\"\n",
    "    # Since we are using the keyfield as a hashtable key, we need to cut out any rows for which it is null.\n",
    "    filled_rows = frame[frame[keyfield].notna()]\n",
    "\n",
    "    # Similarly, we need every value for our keyfield to be unique.\n",
    "    nodupes = filled_rows.drop_duplicates(subset=keyfield)\n",
    "\n",
    "    # We are going to manipulate the dataframe in order to convert it, so let's make a copy to preserve the original.\n",
    "    nodupes = nodupes.copy(deep=True)\n",
    "\n",
    "    # We want to keep the original keyfield in each row, so let's copy it before we make it the dataframe index\n",
    "    nodupes[\"newindex\"]=nodupes[keyfield]\n",
    "    nodupes.set_index(\"newindex\", inplace=True)\n",
    "\n",
    "    # Here we perform the conversion\n",
    "    resultdict = nodupes.to_dict(orient=\"index\")\n",
    "    \n",
    "    # A bit of telemetry here:\n",
    "    if len(resultdict)>0:\n",
    "        # I know it sounds ridiculous to say \"primary-key duplicates\"\n",
    "        # Remember - we are dealing with static csv files, and just *treating* a field *like* a primary key!\n",
    "        print(f\"Converted {framename} to dict of length {len(resultdict)} based on {keyfield}, discarding {len(filled_rows)-len(nodupes)} primary-key duplicates in the process.\")\n",
    "    else:\n",
    "        print(f\"No suitable rows in {framename} to convert to dict based on {keyfield}.\")\n",
    "    \n",
    "    return resultdict\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can convert our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need somewhere to store our hash tables\n",
    "data_dicts = dict()\n",
    "\n",
    "# We loop through each dataset\n",
    "for dataset_name, dataset in data_to_merge.items():\n",
    "    data_dicts[dataset_name] = convert_to_dict(\n",
    "        framename=dataset_name, \n",
    "        frame=dataset, \n",
    "        # PK_FIELDS is one of our constants from the settings section above\n",
    "        keyfield=PK_FIELDS[dataset_name]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding matched records between datasets\n",
    "\n",
    "Next we need a way to figure out when two rows from two different datasets refer to the same person. If we had QUT_IDENTITY_IDs for every dataset this would be a piece of cake, but unfortunately we do not. Instead, we need a workaround.\n",
    "\n",
    "First, let's write a function to identify matched pairs of rows in two datasets, based on some field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches_as_tuples(matchfieldname: str, leftdict: dict, rightdict: dict, leftpk: str, rightpk: str) -> list[tuple[str]]:\n",
    "    \"\"\"Identifies entries in a pair of hash tables that appear to correspond to one another based on some field.\n",
    "\n",
    "        NB: matchfield must not be heavily duplicated in input tables. filter them down if necessary\n",
    "    Args: \n",
    "        matchfieldname: the name of the field on which to align the tables\n",
    "        leftdict: the first table (analagous to the left element of an innner join)\n",
    "        rightdict: the other table\n",
    "        leftpk: the field in leftdict which acts as a primary key\n",
    "        rightpk: the field in rightdict which acts as a primary key\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples of the form (leftpk, rightpk), indicating a linked pair of entries from the two tables\n",
    "    \"\"\"\n",
    "    # We reorient each input table to use the matchfield as its keys, ignoring entries with null keys\n",
    "    # Note that this means if there are multiple rows with the same matchfield value in a table, only the last will count\n",
    "    # For this reason it's a good idea to pick matchfields that are highly unique\n",
    "    newleftdict = {element[matchfieldname]: element for element in leftdict.values() if not element[matchfieldname] is np.nan}\n",
    "    newrightdict = {element[matchfieldname]: element for element in rightdict.values() if not element[matchfieldname] is np.nan}\n",
    "\n",
    "    # This is hard to read, I know. \n",
    "    # We are iterating through each element in newleftdict, and checking if there's an element in newrightdict with the same value for matchfield\n",
    "    # If there is, we record their pkfield values, if not we continue\n",
    "    matches = [(leftelement[leftpk], newrightdict[matchfield][rightpk]) for matchfield, leftelement in newleftdict.items() if matchfield in newrightdict]\n",
    "\n",
    "    # Telemetry\n",
    "    print(f\"Found {len(matches)} matches based on {matchfieldname}.\")\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll collect those links! It may take a bit of trial and error to find the optimal fields for linking. The code below gets it right for the original input data. If your data has changed, YMMV. If all of your datasets have QUT_IDENTITY_ID as a column, you can simplify this process significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A place to store our lists of links\n",
    "linked_entries = dict()\n",
    "\n",
    "# We're using the MATCHFIELDS variable we set up in the settings file to do this in a few lines of code\n",
    "for matchfieldname, dataset_tuples in MATCHFIELDS.items():\n",
    "    for leftset, rightset in dataset_tuples:\n",
    "\n",
    "        # A bit of context for the telemetry\n",
    "        print(f\"\\n{leftset} + {rightset}: \\n\\t\", end=\"\")\n",
    "\n",
    "        # Actually doing the work now\n",
    "        linked_entries[f\"{leftset}__{rightset}\"] = find_matches_as_tuples(\n",
    "            matchfieldname=matchfieldname, \n",
    "            leftdict=data_dicts[leftset], \n",
    "            rightdict=data_dicts[rightset], \n",
    "            leftpk=PK_FIELDS[leftset], \n",
    "            rightpk=PK_FIELDS[rightset]\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement\n",
    "\n",
    "Since we now know which records between sources correspond, we can look at how often those sources agree with each other on a given field's value.\n",
    "\n",
    "First, you guessed it, we need another function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_field_match(leftsourcedict: dict, rightsourcedict: dict, matchedrows: list[tuple[str]], fieldname: str) -> dict:\n",
    "    \"\"\"Evaluates the extent to which datasets with linked rows agree on the values of the fields in those rows.\n",
    "\n",
    "    Args:\n",
    "        leftsourcedict: a hash table containing entries, some of which are linked\n",
    "        rightsourcedict: a hash table containing entries, some of which are those linked to in leftsourcedict\n",
    "        matchedrows: a list of tuples of the form (leftsourcedict_pk, rightsourcedict_pk), indicating which rows are linked\n",
    "        fieldname: the name of the field to compare values on\n",
    "\n",
    "    Returns:\n",
    "        A dict of the form {\"agreeing\": some_int, \"compared\" some_int}\n",
    "    \"\"\"\n",
    "    # Another real eyeful I'm afraid.\n",
    "    # We are making a list of booleans, representing whether or not the values in each linked pair of entries agree for a given field\n",
    "    # Crucially, if one of the values is null, we ignore the pair\n",
    "    evaluations = [leftsourcedict[pair[0]][fieldname]==rightsourcedict[pair[1]][fieldname] for pair in matchedrows if not (leftsourcedict[pair[0]][fieldname] is np.nan or rightsourcedict[pair[1]][fieldname] is np.nan)]\n",
    "\n",
    "    # Then we return a dictionary representing the results\n",
    "    return {\n",
    "        \"agreeing\": len([x for x in evaluations if x is True]),\n",
    "        \"compared\": len(evaluations)\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair, links in linked_entries.items():\n",
    "    # As we iterate through the collections of linked entries, we need to know which datasets they're from\n",
    "    # We can get that from the keys of our dict:\n",
    "    leftsourcedict, rightsourcedict = pair.split(\"__\")\n",
    "    \n",
    "    # We can only evaluate agreement on columns that appear in both datasets, so lets get a list of those:\n",
    "    columns = [column for column in validation_dict.keys() if column in data_to_merge[leftsourcedict].columns and column in data_to_merge[rightsourcedict].columns]\n",
    "    \n",
    "    # We're running our function twice here which is inefficient, but the datasets aren't big enough for that to matter\n",
    "    to_display = pd.DataFrame({\n",
    "        \"columns\": columns,\n",
    "        \"compared\": [evaluate_field_match(data_dicts[leftsourcedict], data_dicts[rightsourcedict], links, column)[\"compared\"] for column in columns],\n",
    "        \"agreeing\": [evaluate_field_match(data_dicts[leftsourcedict], data_dicts[rightsourcedict], links, column)[\"agreeing\"] for column in columns], \n",
    "    })\n",
    "\n",
    "    to_display[\"agreement\"] = to_display[\"agreeing\"]/to_display[\"compared\"]\n",
    "\n",
    "    print(f\"\\n\\n{pair}: \")\n",
    "    display(to_display.style.format({\n",
    "            \"agreement\": '{:,.2%}'.format\n",
    "        }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there are a couple here where the sample size is too small to be considered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Merge\n",
    "\n",
    "The linked entries we calculated earlier look something like this, accounting for a little wiggle-room in the numbers. (The technique has been refined a little since this graphic was created.)\n",
    "\n",
    "![Merge links topology](./img/merge_links.drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly put together a list of all the fields in all our datasets\n",
    "all_fields =  set()\n",
    "for dataset in data_to_merge.values():\n",
    "    all_fields = all_fields | set(dataset.columns)\n",
    "\n",
    "# We are going to create one giant hash-table, with an entry for each mastered person, and a sub-hash-table to record each system's value for each field\n",
    "# To do this, we need a function that generates that sub-hash-table-tree\n",
    "def def_value():\n",
    "    fields = {field: dict() for field in all_fields}\n",
    "    # We're also throwing in some information about personae here\n",
    "    fields.update({\n",
    "        \"is_staff\": False, \n",
    "        \"is_applicant\": False,  \n",
    "        \"is_student\": False, \n",
    "        \"is_prospect\": False\n",
    "    })\n",
    "    return fields\n",
    "\n",
    "# This is our one giant hash table\n",
    "master_persons = defaultdict(def_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of what one entry in our putative master person merge might look like. \n",
    "(This data is based on a real entry, but all values have been either redacted or modified. The individual was both a Studylink applicant and a SAMS student, and happened to have a mononym!):\n",
    "\n",
    "```\n",
    "'SOME-QUT-IDENTITY-ID-xxxxxxxxxxxx': {\n",
    "    'APPLICANT_ID': {'studylink_applicants': '6257xxx'},\n",
    "    'SUBRB_HOME': {'sams_students': 'Albion'},\n",
    "    'STATE_HOME': {'sams_students': 'QLD'},\n",
    "    'ADDR2_HOME': {'sams_students': '1 Mayfair'},\n",
    "    'STUDENT_ID': {\n",
    "        'sams_students': '1110xxxx',\n",
    "        'studylink_applicants': '1110xxxx'\n",
    "    },\n",
    "    'CONTACT_ID': {},\n",
    "    'FAMILY_NAME': {\n",
    "        'sams_students': '-',\n",
    "        'studylink_applicants': 'veronica'},\n",
    "    'DOB': {\n",
    "        'sams_students': '1993-xx-xx', \n",
    "        'studylink_applicants': '1993-xx-xx'\n",
    "    },\n",
    "    'SALUTATION': {\n",
    "        'sams_students': 'mrs', \n",
    "        'studylink_applicants': 'mrs'\n",
    "    },\n",
    "    'ADDR3_HOME': {'sams_students': nan},\n",
    "    'GIVEN_NAME': {\n",
    "        'sams_students': 'veronica',\n",
    "        'studylink_applicants': nan\n",
    "    },\n",
    "    'OTHER_NAME': {'sams_students': nan},\n",
    "    'GENDER': {\n",
    "        'sams_students': 'F', \n",
    "        'studylink_applicants': 'F'\n",
    "    },\n",
    "    'EMPLOYEE_ID': {},\n",
    "    'PREFERRED_NAME': {\n",
    "        'sams_students': 'veronica',\n",
    "        'studylink_applicants': nan\n",
    "    },\n",
    "    'PHONE_MOBILE': {\n",
    "        'sams_students': '614564xxxxx',\n",
    "        'studylink_applicants': '614564xxxxx'\n",
    "    },\n",
    "    'PERSONAL_EMAIL': {\n",
    "        'sams_students': 'veronica08@gmail.com',\n",
    "        'studylink_applicants': 'myemail1993@gmail.com'\n",
    "    },\n",
    "    'FULL_NAME': {},\n",
    "    'CNTRY_HOME': {\n",
    "        'sams_students': 'AUS', \n",
    "        'studylink_applicants': 'AUSTRALIA'\n",
    "    },\n",
    "    'ADDR1_HOME': {'sams_students': 'Unit 999'},\n",
    "    'POSTC_HOME': {'sams_students': '4007'},\n",
    "    'is_staff': False,\n",
    "    'is_applicant': True,\n",
    "    'is_student': True,\n",
    "    'is_prospect': False\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of delicate surgery here:\n",
    "\n",
    "# First we add an entry for every SAMS student. Since we used the QUT_IDENTITY_ID field as the keys for this hash table, this is an easy 1-1 mapping.  \n",
    "for index, row in data_dicts[\"sams_students\"].items():\n",
    "    for field, value in row.items():\n",
    "        master_persons[index][field][\"sams_students\"] = value\n",
    "    master_persons[index][\"is_student\"] = True\n",
    "\n",
    "# Ditto for the SAMS applicants. Note that there are a handful of entries that are in both tables, and for these entries we now have multiple values for most fields\n",
    "for index, row in data_dicts[\"sams_applicants\"].items():\n",
    "    for field, value in row.items():\n",
    "        master_persons[index][field][\"sams_applicants\"] = value\n",
    "    master_persons[index][\"is_applicant\"] = True\n",
    "\n",
    "# Ascender employees aren't keyed by QUT_IDENTITY_ID, but we can pull out the matches by looking at the links we calculated earlier, and update the existing entries based on them.\n",
    "for matchpair in linked_entries[\"ascender_employees__sams_students\"]:\n",
    "    # We are popping rows out here because we need to hang on to the unlinked entries in order to insert them later\n",
    "    row = data_dicts[\"ascender_employees\"].pop(matchpair[0])\n",
    "    for field, value in row.items():\n",
    "        master_persons[matchpair[1]][field][\"ascender_employees\"] = value\n",
    "    master_persons[matchpair[1]][\"is_staff\"] = True\n",
    "\n",
    "# Once we've iterated through the links between employees and SAMS students, we can do the same for employees vs SAMS applicants\n",
    "for matchpair in linked_entries[\"ascender_employees__sams_applicants\"]:\n",
    "    # This time we need to check that the linked entry isn't one we already popped out because it was linked to a SAMS student\n",
    "    if matchpair[0] in data_dicts[\"ascender_employees\"]:\n",
    "        row = data_dicts[\"ascender_employees\"].pop(matchpair[0])\n",
    "        for field, value in row.items():\n",
    "            master_persons[matchpair[1]][field][\"ascender_employees\"] = value\n",
    "        master_persons[matchpair[1]][\"is_staff\"] = True\n",
    "\n",
    "# We can do the same for studylink applicants that are linked to SAMS students now.\n",
    "for matchpair in linked_entries[\"sams_students__studylink_applicants\"]:\n",
    "    row = data_dicts[\"studylink_applicants\"].pop(matchpair[1])\n",
    "    for field, value in row.items():\n",
    "        master_persons[matchpair[0]][field][\"studylink_applicants\"] = value\n",
    "    master_persons[matchpair[0]][\"is_applicant\"] = True\n",
    "\n",
    "# Same for the studylink applicants that are linked to SAMS applicants\n",
    "for matchpair in linked_entries[\"studylink_applicants__sams_applicants\"]:\n",
    "    # once again, we need to check that the linked entry isn't one we already popped out because it was linked to a SAMS student\n",
    "    if matchpair[0] in data_dicts[\"studylink_applicants\"]:\n",
    "        row = data_dicts[\"studylink_applicants\"].pop(matchpair[0])\n",
    "        for field, value in row.items():\n",
    "            master_persons[matchpair[1]][field][\"studylink_applicants\"] = value\n",
    "        master_persons[matchpair[0]][\"is_applicant\"] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick pause to assess where we are up to in our surgery:\n",
    "\n",
    "We've rolled in ALL of the records from SAMS, as well as any records we can link to them from Ascender and Studylink.\n",
    "\n",
    "Taking a look at the merge link topology diagram above, we can see that there is only one remaining link so account for - the one between DEP and Ascender. However, since we haven't rolled in all of our Ascender records yet, there's no guarantee that we can bring that final link in. Let's get all the other datasets fully folded in first before we try to add in that last link.\n",
    "\n",
    "Up until now we have only dealt with records that we knew had a value for QUT_IDENTITY_ID. Since our Master Person dataset is keyed based on QUT_IDENTITY_ID, we need to make sure that all the remaining records have a value for that field. Where the value is missing, we will forge a fake ID for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for source in [\"ascender_employees\", \"studylink_applicants\", \"dep_prospects\"]:\n",
    "    for row, fields in data_dicts[source].items():\n",
    "        if (\"QUT_GUID\" in fields and fields[\"QUT_GUID\"] is np.nan) or not \"QUT_GUID\" in fields:\n",
    "            data_dicts[source][row][\"QUT_GUID\"] = f\"NOID_{count}\"\n",
    "            count +=1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can roll in the remaining ascender and studylink records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, fields in data_dicts[\"ascender_employees\"].items():\n",
    "    for field, value in fields.items():\n",
    "        master_persons[fields[\"QUT_GUID\"]][field][\"ascender_employees\"] = value\n",
    "    master_persons[fields[\"QUT_GUID\"]][\"is_staff\"] = True\n",
    "\n",
    "for row, fields in data_dicts[\"studylink_applicants\"].items():\n",
    "    for field, value in fields.items():\n",
    "        master_persons[fields[\"QUT_GUID\"]][field][\"studylink_applicants\"] = value\n",
    "    master_persons[fields[\"QUT_GUID\"]][\"is_applicant\"] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can link in that pesky DEP record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matchpair in linked_entries[\"dep_prospects__ascender_employees\"]:\n",
    "    row = data_dicts[\"dep_prospects\"].pop(matchpair[0])\n",
    "    for field, value in row.items():\n",
    "        master_persons[matchpair[1]][field][\"dep_prospects\"] = value\n",
    "    master_persons[matchpair[1]][\"is_prospect\"] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the rest of the DEP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, fields in data_dicts[\"dep_prospects\"].items():\n",
    "    for field, value in fields.items():\n",
    "        master_persons[fields[\"QUT_GUID\"]][field][\"dep_prospects\"] = value\n",
    "    master_persons[fields[\"QUT_GUID\"]][\"is_prospect\"] = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! Let's take a look at what we have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"staff: {len([x for x in master_persons.values() if x['is_staff']])}\")\n",
    "print(f\"students: {len([x for x in master_persons.values() if x['is_student']])}\")\n",
    "print(f\"applicants: {len([x for x in master_persons.values() if x['is_applicant']])}\")\n",
    "print(f\"prospects: {len([x for x in master_persons.values() if x['is_prospect']])}\")\n",
    "print(\"-----\")\n",
    "print(f\"people who are both staff AND student: {len([x for x in master_persons.values() if (x['is_staff'] and x['is_student'])])}\")\n",
    "print(f\"people who are both staff AND applicant: {len([x for x in master_persons.values() if (x['is_staff'] and x['is_applicant'])])}\")\n",
    "print(f\"people who are both student AND applicant: {len([x for x in master_persons.values() if (x['is_applicant'] and x['is_student'])])}\")\n",
    "print(\"-----\")\n",
    "print(f\"people who are staff AND applicant AND staff: {len([x for x in master_persons.values() if (x['is_applicant'] and x['is_student'] and x['is_staff'])])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not every person who has an entry in more than one system has more than one value for every field (some fields are null). \n",
    "# So how many of each field has multiple values recorded against it?\n",
    "def returns_0():\n",
    "    return 0\n",
    "\n",
    "multi_value_counts = defaultdict(returns_0)\n",
    "\n",
    "for row, fields in master_persons.items():\n",
    "    for field, values in fields.items():\n",
    "        if isinstance(values, dict) and len(list(filter(lambda y: not y is np.nan, values.values()))) > 1:\n",
    "            multi_value_counts[field] += 1\n",
    "\n",
    "\n",
    "# For those people who had entries in more than one system, how many of them had different values for their fields in different systems?\n",
    "differing_value_counts = defaultdict(returns_0)\n",
    "\n",
    "for row, fields in master_persons.items():\n",
    "    for field, values in fields.items():\n",
    "        if isinstance(values, dict) and len(set(filter(lambda y: not y is np.nan, values.values()))) > 1:\n",
    "            differing_value_counts[field] += 1\n",
    "\n",
    "\n",
    "# We can use that info to calculate consistency for the master person \n",
    "# (for the individual systems we didn't have a good way to measure this, so we used agreement as a proxy measure)\n",
    "consistency_frame = pd.DataFrame({\n",
    "    \"fields\": [field for field in FIELD_SYSTEM_PRECEDENCES],\n",
    "    \"entries with multiple values\": [multi_value_counts[field] if field in multi_value_counts else 0 for field in FIELD_SYSTEM_PRECEDENCES],\n",
    "    \"entries with inconsistent values\": [differing_value_counts[field] if field in differing_value_counts else 0 for field in FIELD_SYSTEM_PRECEDENCES]\n",
    "})\n",
    "consistency_frame[\"consistency\"] = 1 - consistency_frame[\"entries with inconsistent values\"]/consistency_frame[\"entries with multiple values\"]\n",
    "\n",
    "display(consistency_frame.style.format({\n",
    "            # we apply a little styling to our temp dataframe so that the validity column is displayed as a percentage\n",
    "            \"consistency\": '{:,.2%}'.format\n",
    "        }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of interest, let's take a look at how many people have multiple different VALID values for each field. Note that we aren't validating addresses, so they're not included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differing_valid_value_counts = defaultdict(returns_0)\n",
    "\n",
    "for row, fields in master_persons.items():\n",
    "    for field, values in fields.items():\n",
    "        if isinstance(values, dict) and field in validation_dict and len(set(filter(lambda y: not y is np.nan and (validation_dict[field](y)), values.values()))) > 1:\n",
    "            differing_valid_value_counts[field] += 1\n",
    "\n",
    "for field, count in differing_valid_value_counts.items():\n",
    "    print(f\"{field}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsing the field possibilities\n",
    "\n",
    "Where we have more than one possible value for a field given to us by different systems, we want to pick the best value. We'll be using the FIELD_SYSTEM_PREFERENCES we set down in the settings section. These are based on the agreement measures we calculated earlier - the higher a system's overall agreement, the higher its priority. Let's write a function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_value(field_name, field_values):\n",
    "    # If this isn't a dict of possible values, just return it as-is \n",
    "    if not isinstance(field_values, dict):\n",
    "        return field_values\n",
    "\n",
    "    # If we haven't listed a preference order for this field, we don't need it in the master person, so return null    \n",
    "    if not field in FIELD_SYSTEM_PRECEDENCES:\n",
    "        return np.nan\n",
    "\n",
    "    # Grab all the non-null values\n",
    "    non_null_values = {source: value for source, value in field_values.items() if not value is np.nan}\n",
    "\n",
    "    # If there are no non-null values in the options, set the field to null\n",
    "    if not non_null_values:\n",
    "        return np.nan\n",
    "\n",
    "    # If this is a field we don't have a way of validating, return the preferred source's non-null value\n",
    "    if not field_name in validation_dict:\n",
    "        for source in FIELD_SYSTEM_PRECEDENCES[field_name]:\n",
    "            if source in non_null_values:\n",
    "                return non_null_values[source]\n",
    "\n",
    "    # Now grab all the valid values\n",
    "    valid_values = {source: value for source, value in non_null_values.items() if validation_dict[field_name](value)}\n",
    "\n",
    "    # If there are no valid values, take the preferred source's invalid value\n",
    "    if not valid_values:\n",
    "        for source in FIELD_SYSTEM_PRECEDENCES[field_name]:\n",
    "            if source in non_null_values:\n",
    "                return non_null_values[source]\n",
    "\n",
    "    # Finally, if you got this far, take the preferred source's valid value\n",
    "    for source in FIELD_SYSTEM_PRECEDENCES[field_name]:\n",
    "        if source in valid_values:\n",
    "            return valid_values[source]\n",
    "\n",
    "\n",
    "# Let's use that function to collapse the fields:\n",
    "final_master_persons = dict()\n",
    "\n",
    "for id, person in master_persons.items():\n",
    "    final_master_persons[id] = dict()\n",
    "    for field, values in person.items():\n",
    "        final_master_persons[id][field] = choose_value(field, values)\n",
    "        final_master_persons[id][\"QUT_GUID\"] = id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have just one value per field for each record, we can convert our master persons back to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_frame = pd.DataFrame.from_dict(final_master_persons, orient='index').drop(columns=['APPLICANT_ID', 'STUDENT_ID', 'CONTACT_ID', 'EMPLOYEE_ID'])\n",
    "master_frame.to_csv(\"master_frame.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Person Completeness\n",
    "\n",
    "Let's calculate the completeness for the master person data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(master_frame)\n",
    "\n",
    "# Then we create a temporary dataframe to hold our calculations\n",
    "to_display = pd.DataFrame({\n",
    "    # The first column of the temp dataframe contains the names of each column in the dataset\n",
    "    \"column\": [column for column in master_frame.columns],\n",
    "    # The second column shows how many non-null values there are for each column\n",
    "    \"count\": [len(master_frame[master_frame[column].notna()]) for column in master_frame.columns],\n",
    "    # The third column calculates the relative frequency of non-null values \n",
    "    \"completeness\": [len(master_frame[master_frame[column].notna()])/dataset_length for column in master_frame.columns],\n",
    "    # The fourth column gives us an example value from the column\n",
    "    \"sample\": [master_frame[master_frame[column].notna()][column].mode()[0] if len(master_frame[master_frame[column].notna()][column]) else np.nan for column in master_frame]\n",
    "# we apply a little styling to our temp dataframe so that the completeness column is displayed as a percentage\n",
    "}).style.format({\n",
    "    \"completeness\": '{:,.2%}'.format\n",
    "})\n",
    "\n",
    "# This display() function is the one we imported from Ipython up the top - it just improves readability\n",
    "display(to_display)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Person Validity\n",
    "\n",
    "Same for validity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need one temp frame to hold the results of our validations\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "    validity_frame = pd.DataFrame()\n",
    "\n",
    "    # our validity_frame mirrors the\n",
    "    for column in master_frame.columns:\n",
    "        if column in validation_dict:\n",
    "            validity_frame[column] = master_frame[column].apply(validation_dict[column])    \n",
    "\n",
    "    to_display = pd.DataFrame({\n",
    "        # The first column of the temp dataframe contains the names of each column in the dataset\n",
    "        \"column\": [column for column in validity_frame.columns],\n",
    "        # The second column shows how many non-null values there are for each column\n",
    "        \"count\": [len(master_frame[master_frame[column].notna()]) for column in validity_frame.columns],\n",
    "        # The third column calculates how many valid values there are in each column \n",
    "        \"valid\": [len(validity_frame[validity_frame[column].notna()][validity_frame[column]==True]) for column in validity_frame.columns],\n",
    "    \n",
    "    })\n",
    "\n",
    "    # Finally let's add another column to show validity as a percentage\n",
    "    to_display[\"validity\"] = to_display[\"valid\"]/to_display[\"count\"]\n",
    "\n",
    "    display(to_display.style.format({\n",
    "        # we apply a little styling to our temp dataframe so that the validity column is displayed as a percentage\n",
    "        \"validity\": '{:,.2%}'.format\n",
    "    }))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Person Uniqueness\n",
    "\n",
    "Finally, we can take a look at uniqueness for the master person records. This also gives us an idea of the stewardship requirements that our master person system will have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdh_frame_copy = master_frame.copy(deep=True)\n",
    "\n",
    "mobilename_quarantine=find_dupes(mdh_frame_copy, \"QUT_GUID\", \"GIVEN_NAME\", \"PHONE_MOBILE\")\n",
    "print(f\"Quarantined {len(mobilename_quarantine)} rows based on mobile + firstname\")\n",
    "mobiledob_quarantine=find_dupes(mdh_frame_copy, \"QUT_GUID\", \"DOB\", \"PHONE_MOBILE\")\n",
    "print(f\"Quarantined {len(mobiledob_quarantine)} rows based on mobile + dob\")\n",
    "emailname_quarantine=find_dupes(mdh_frame_copy, \"QUT_GUID\", \"GIVEN_NAME\", \"PERSONAL_EMAIL\")\n",
    "print(f\"Quarantined {len(emailname_quarantine)} rows based on email + firstname\")\n",
    "emaildob_quarantine=find_dupes(mdh_frame_copy, \"QUT_GUID\", \"DOB\", \"PERSONAL_EMAIL\")\n",
    "print(f\"Quarantined {len(emaildob_quarantine)} rows based on email + dob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_master_dupes = pd.concat([mobilename_quarantine, mobiledob_quarantine, emailname_quarantine, emaildob_quarantine]).drop_duplicates(subset=\"QUT_GUID\", keep='first')\n",
    "print(f\"Total records quarantined: {len(all_master_dupes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Master person uniqueness: {'{0:.2%}'.format(1- len(all_master_dupes)/len(mdh_frame_copy))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47085bc4215bf6b1262177bc913a1f151c8171a3706891bbd3e98bbf73e25f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
